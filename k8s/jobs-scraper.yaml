apiVersion: apps/v1
kind: Deployment
metadata:
  name: jobs-scraper
  labels:
    app: jobs-scraper
spec:
  replicas: 1  # 爬虫服务通常只需要一个实例
  selector:
    matchLabels:
      app: jobs-scraper
  template:
    metadata:
      labels:
        app: jobs-scraper
    spec:
      containers:
      - name: jobs-scraper
        image: your-registry/jobs-scraper:latest
        env:
        - name: API_BASE_URL
          value: "http://jobs-api-service/api"
        - name: API_TOKEN
          valueFrom:
            secretKeyRef:
              name: jobs-secrets
              key: scraper-api-token
              optional: true
        resources:
          limits:
            cpu: 1000m
            memory: 2Gi
          requests:
            cpu: 500m
            memory: 1Gi
        # 为Chrome和爬虫操作添加安全上下文
        securityContext:
          allowPrivilegeEscalation: false
          runAsNonRoot: true
          runAsUser: 1000
          capabilities:
            drop:
            - ALL
        # 添加临时卷用于Chrome缓存
        volumeMounts:
        - name: tmp-volume
          mountPath: /tmp
        - name: cache-volume
          mountPath: /home/scraper/.cache
      volumes:
      - name: tmp-volume
        emptyDir: {}
      - name: cache-volume
        emptyDir: {}
      restartPolicy: Always

---
# 可选：为爬虫服务创建一个Service，用于健康检查或内部通信
apiVersion: v1
kind: Service
metadata:
  name: jobs-scraper-service
spec:
  selector:
    app: jobs-scraper
  ports:
    - protocol: TCP
      port: 8080
      targetPort: 8080
  type: ClusterIP

---
# CronJob 用于定时触发爬虫任务
apiVersion: batch/v1
kind: CronJob
metadata:
  name: jobs-scraper-trigger
spec:
  schedule: "0 */6 * * *"  # 每6小时运行一次
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: scraper-trigger
            image: curlimages/curl:latest
            command:
            - /bin/sh
            - -c
            - |
              echo "触发爬虫任务..."
              curl -X POST http://jobs-api-service/api/jobs/scraper/trigger \
                -H "Content-Type: application/json" \
                -d '{"source": "cron"}' \
                --max-time 30 \
                --retry 3
              echo "触发完成"
          restartPolicy: OnFailure